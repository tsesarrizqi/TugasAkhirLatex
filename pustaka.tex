%
% Daftar Pustaka 
% 

% 
% Tambahkan pustaka yang digunakan setelah perintah berikut. 
% 
\phantomsection %hack to add clickable section for pustaka
\begin{thebibliography}{4}

\bibitem{deeplearning}
{LeCun, Y., Bengio, Y., \& Hinton, G. (2015). Deep learning. Nature, 521(7553), 436–444. https://doi.org/10.1038/nature14539}

\bibitem{inception}
{Szegedy, C., Wei Liu, Yangqing Jia, Sermanet, P., Reed, S., Anguelov, D., … Rabinovich, A. (2015). Going deeper with convolutions. In 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE. https://doi.org/10.1109/cvpr.2015.7298594}

\bibitem{alexnet}
{Krizhevsky, A., Sutskever, I., \& Hinton, G. E. (2017). ImageNet classification with deep convolutional neural networks. Communications of the ACM, 60(6), 84–90. https://doi.org/10.1145/3065386}

\bibitem{vgg}
{Liu, S., \& Deng, W. (2015). Very deep convolutional neural network based image classification using small training sample size. In 2015 3rd IAPR Asian Conference on Pattern Recognition (ACPR). IEEE. https://doi.org/10.1109/acpr.2015.7486599}

\bibitem{ilsvrc}
{Russakovsky, O., Deng, J., Su, H. et al. Int J Comput Vis (2015) 115: 211. https://doi.org/10.1007/s11263-015-0816-y}

\bibitem{cnn}
{O'Shea, Keiron \& Nash, Ryan. (2015). An Introduction to Convolutional Neural Networks. ArXiv e-prints.}

\bibitem{tensorflow}
{Martín Abadi, dkk.. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. Software available from tensorflow.org.}

\bibitem{checkpoint}
{Saving and Restoring  |  TensorFlow. (n.d.). Retrieved December 19, 2017, from https://www.tensorflow.org/programmers\_guide/saved\_model}

\bibitem{frozengraph}
{A Tool Developer's Guide to TensorFlow Model Files  |  TensorFlow. (n.d.). Retrieved December 19, 2017, from https://www.tensorflow.org/extend/tool\_developers/\#freezing}

\bibitem{fixedquantization}
{Darryl D. Lin, Sachin S. Talathi, and V. Sreekanth Annapureddy. 2016. Fixed point quantization of deep convolutional networks. In Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48 (ICML'16), Maria Florina Balcan and Kilian Q. Weinberger (Eds.), Vol. 48. JMLR.org 2849-2858.}

\bibitem{floatingweightfixedactivation}
{Chandra, V., Lai, L., \& Suda, N. (2017). Deep Convolutional Neural Network Inference with Floating-point Weights and Fixed-point Activations. CoRR, abs/1703.03073.}

\bibitem{cnndroid}
{Latifi Oskouei, S. S., Golestani, H., Hashemi, M., \& Ghiasi, S. (2016). CNNdroid. In Proceedings of the 2016 ACM on Multimedia Conference - MM ’16. ACM Press. https://doi.org/10.1145/2964284.2973801}

\bibitem{tensorquantization}
{How to Quantize Neural Networks with TensorFlow  |  TensorFlow. (n.d.). Retrieved December 20, 2017, from https://www.tensorflow.org/performance/quantization}

\bibitem{caffe}
{B. (2017, November 29). BVLC/caffe. Retrieved December 20, 2017, from https://github.com/BVLC/caffe}

\bibitem{deomposition}
{Jaderberg, M., Vedaldi, A., \& Zisserman, A. (2014). Speeding up Convolutional Neural Networks with Low Rank Expansions. In Proceedings of the British Machine Vision Conference 2014. British Machine Vision Association. https://doi.org/10.5244/c.28.88}

\bibitem{gpuenergy}
{Huang, S., Xiao, S., \& Feng, W. (2009). On the energy efficiency of graphics processing units for scientific computing. In 2009 IEEE International Symposium on Parallel \& Distributed Processing. IEEE. https://doi.org/10.1109/ipdps.2009.5160980}

\end{thebibliography}

